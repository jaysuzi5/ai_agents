{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce59910",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e518321",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LangGraph Jira\n",
    "This example exands on the second example and will have a similar flow except for the last agent/node that will call a new agent that will load the data to Jira using a LangChain tool.  Overall, this example will demonstrate a BSA agent that creates requirements, and evaluator to make sure they are complete, and then a recorder node that will enter them into Jira."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739f0d3",
   "metadata": {},
   "source": [
    "### 1. Load the needed libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from typing import List, Any, Optional, Annotated, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import sqlite3\n",
    "import gradio \n",
    "\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import BaseTool\n",
    "from langsmith import uuid7\n",
    "from langchain_community.tools import Tool\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n",
    "from langchain_community.tools.wikipedia.tool import WikipediaQueryRun\n",
    "from langchain_community.agent_toolkits.jira.toolkit import JiraToolkit\n",
    "from langchain_community.utilities.jira import JiraAPIWrapper\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41e526",
   "metadata": {},
   "source": [
    "### 2. Add Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tools() -> List[BaseTool]:\n",
    "    # Define server, wrapper around the Google API, as a tool\n",
    "    tool_search: Tool = Tool(\n",
    "        name=\"search\",\n",
    "        func=GoogleSerperAPIWrapper().run,\n",
    "        description=\"Use this tool when you want to get the results of an online web search\"\n",
    "    )\n",
    "\n",
    "    # Define Wikipedia as a search as a tool\n",
    "    wikipedia: WikipediaAPIWrapper = WikipediaAPIWrapper()\n",
    "    wiki_tool: WikipediaQueryRun = WikipediaQueryRun(api_wrapper=wikipedia)\n",
    "\n",
    "    # Define file management tools\n",
    "    file_tools: List[BaseTool] = FileManagementToolkit(root_dir=\"sandbox\").get_tools()\n",
    "\n",
    "    # Concatenate all tools together as a list\n",
    "    tools: List[BaseTool] = file_tools + [tool_search, wiki_tool]\n",
    "\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc0a92",
   "metadata": {},
   "source": [
    "### 2a. Add Tools for the Recorder agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c939b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recorder_tools() -> List[BaseTool]:\n",
    "    # Define file management tools\n",
    "    file_tools: List[BaseTool] = FileManagementToolkit(root_dir=\"sandbox\").get_tools()\n",
    "\n",
    "    # Define Jira tools\n",
    "    jira_api = JiraAPIWrapper()\n",
    "    jira_toolkit = JiraToolkit.from_jira_api_wrapper(jira_api)\n",
    "    jira_tools: List[BaseTool] = jira_toolkit.get_tools()\n",
    "    \n",
    "    # Add a custom tool to list available Jira fields\n",
    "    def list_jira_fields(query: str = \"\") -> str:\n",
    "        \"\"\"Get all available fields for creating issues in Jira. The query parameter is optional.\"\"\"\n",
    "        try:\n",
    "            # Access the underlying Jira client to get field information\n",
    "            fields = jira_api.jira.fields()\n",
    "            available_fields = []\n",
    "            for field in fields:\n",
    "                available_fields.append({\n",
    "                    \"id\": field.get(\"id\"),\n",
    "                    \"name\": field.get(\"name\"),\n",
    "                    \"schema\": field.get(\"schema\", {}).get(\"type\", \"unknown\")\n",
    "                })\n",
    "            \n",
    "            # Format the output to be readable\n",
    "            field_list = \"Available Jira Fields:\\n\"\n",
    "            for field in available_fields:\n",
    "                field_list += f\"- {field['name']} (ID: {field['id']}, Type: {field['schema']})\\n\"\n",
    "            return field_list\n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving fields: {str(e)}\"\n",
    "    \n",
    "    fields_tool = Tool(\n",
    "        name=\"list_jira_fields\",\n",
    "        func=list_jira_fields,\n",
    "        description=\"List all available Jira fields that can be used when creating issues. Use this to understand what fields are accessible before creating issues.\"\n",
    "    )\n",
    "    \n",
    "    # Concatenate all tools together as a list\n",
    "    tools: List[BaseTool] = file_tools + jira_tools + [fields_tool]\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043a674",
   "metadata": {},
   "source": [
    "### 3. Setup Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"memory.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "sql_memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79179fae",
   "metadata": {},
   "source": [
    "### 4. Build the Graph\n",
    "It is now time to put start building the graph.  All graphs include the following steps:\n",
    "<ol>\n",
    "<li>Define the State</li>\n",
    "<li>Start Graph Builder</li>\n",
    "<li>Create Nodes</li>\n",
    "<li>Create Edges</li>\n",
    "<li>Compile the Graph</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a48ed",
   "metadata": {},
   "source": [
    "### State with additional details\n",
    "Will track additional details in the state to help with routing:\n",
    "<ul>\n",
    "<li>file_name: name of the file</li>\n",
    "<li>feedback_on_work: details from the evaluator</li>\n",
    "<li>success_criteria_met: determines if it should end</li>\n",
    "<li>number_of_reviews: the number of reviews completed as a guardrail from looping too much</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the State object\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    file_name: str\n",
    "    feedback_on_work: Optional[str]\n",
    "    success_criteria_met: bool\n",
    "    number_of_reviews: int=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Start the Graph Builder with this State class\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47185838",
   "metadata": {},
   "source": [
    "#### Define the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1608bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsa_system_message = \"\"\"\n",
    "You are a Business Systems Analyst (BSA), an autonomous agent specializing in transforming a short requirement into a complete set of functional and non-functional requirements, user stories, and acceptance criteria. You have access to tools including Google Search, Wikipedia, and file management tools (read_file, write_file, list_directory, delete_file).\n",
    "\n",
    "Your responsibilities include:\n",
    "1. Analyzing the user-provided requirement.\n",
    "2. Asking clarifying questions **before beginning any writing**, if the requirement is ambiguous or incomplete.\n",
    "3. Extracting and defining functional and non-functional requirements.\n",
    "4. Converting each requirement into one or more user stories.\n",
    "5. Writing acceptance criteria for every user story.\n",
    "6. Compiling all output into a properly structured markdown file.\n",
    "7. Saving the final markdown file to disk using the write_file tool.\n",
    "\n",
    "TOOL USAGE RULES:\n",
    "- You MUST NOT call write_file until the entire markdown document is fully generated.\n",
    "- Only use search tools when information cannot be derived from the provided requirement.\n",
    "- ALWAYS ask clarifying questions if the requirement is not sufficient to generate high-quality user stories.\n",
    "\n",
    "OUTPUT REQUIREMENTS:\n",
    "\n",
    "1. The final output MUST be a single markdown file with the following structure:\n",
    "\n",
    "   # Overview  \n",
    "   # Functional Requirements  \n",
    "   # Non-Functional Requirements  \n",
    "   # User Stories  \n",
    "   ## <User Story Title>  \n",
    "   - User Story  \n",
    "   - Acceptance Criteria  \n",
    "\n",
    "2. Each User Story MUST follow the exact pattern:\n",
    "       As a <type of user>,\n",
    "       I want <goal or action>,\n",
    "       So that <reason or value>.\n",
    "\n",
    "3. Each requirement must produce at least one user story.  \n",
    "   If a requirement implies multiple user needs, generate multiple user stories.\n",
    "\n",
    "4. Each User Story MUST include **at least one** Acceptance Criteria, and as many as needed for full clarity.\n",
    "\n",
    "5. All Acceptance Criteria MUST follow the exact Given/When/Then pattern:\n",
    "       Given <precondition>\n",
    "       When <action>\n",
    "       Then <expected outcome>\n",
    "\n",
    "6. Tone rules:\n",
    "   - Use a neutral, authoritative, academic tone for descriptions, lists, analyses, and requirement sections.\n",
    "   - User stories themselves should retain standard conversational user-story tone.\n",
    "\n",
    "FILENAME REQUIREMENTS (MANDATORY):\n",
    "\n",
    "You MUST save the final markdown file using the write_file tool.\n",
    "\n",
    "The filename MUST follow this exact format:\n",
    "       YYYYMMDDHHmmss_<requirement_summary>.md\n",
    "\n",
    "Where:\n",
    "- YYYYMMDDHHmmss is the current UTC timestamp (year, month, day, hour, minute, second).\n",
    "- <requirement_summary> is a short, snake_case summary of the requirement:  \n",
    "      - all lowercase  \n",
    "      - alphanumeric plus underscores  \n",
    "      - no spaces  \n",
    "      - concise (ideally 3–6 words)\n",
    "\n",
    "\n",
    "BEHAVIOR RULES:\n",
    "- NEVER skip functional or non-functional requirements.\n",
    "- ALWAYS ensure full coverage: no part of the requirement should remain unmapped to a story.\n",
    "- NEVER call write_file until the markdown document is 100% complete.\n",
    "- WRITE ALL requirements to a single file.\n",
    "- ALWAYS confirm the file has been saved after using write_file.\n",
    "\n",
    "FINAL WORKFLOW:\n",
    "1. Parse the user requirement.\n",
    "2. Ask clarifying questions if needed.\n",
    "3. Generate functional requirements.\n",
    "4. Generate non-functional requirements.\n",
    "5. Convert all requirements into user stories.\n",
    "6. Define acceptance criteria for each story.\n",
    "7. Compile the full markdown report.\n",
    "8. Save to disk using write_file with the required filename format.\n",
    "9. Confirm the file has been saved.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da89315",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_message = \"\"\"\n",
    "You are BSAReviewAgent, an autonomous quality-control reviewer responsible for evaluating the output generated by the BSA (Business Systems Analyst) agent.\n",
    "You must evaluate the markdown requirements document strictly. \n",
    "\n",
    "Your responsibilities:\n",
    "\n",
    "1. Evaluate whether the markdown file complies with the naming and formatting requirements\n",
    "\n",
    "   A. File & Output Validation\n",
    "      - A markdown file MUST exist in the sandbox directory.\n",
    "      - The filename MUST follow the exact required format:\n",
    "            YYYYMMDDHHmmss_<requirement_summary>.md\n",
    "      - The filename MUST use UTC timestamps.\n",
    "      - The requirement summary MUST be lowercase, snake_case, concise, and contain only a–z, 0–9, and underscores.\n",
    "\n",
    "   B. User Story Requirements\n",
    "      - EVERY user story MUST follow the exact template:\n",
    "            As a <type of user>,\n",
    "            I want <goal or action>,\n",
    "            So that <reason or value>.\n",
    "\n",
    "   C. Acceptance Criteria Requirements\n",
    "      - Each user story MUST have at least one acceptance criteria section.\n",
    "      - ALL acceptance criteria MUST follow the Gherkin-style Given/When/Then format exactly:\n",
    "            Given <precondition>\n",
    "            When <action>\n",
    "            Then <expected outcome>\n",
    "\n",
    "\n",
    "2. If ALL success criteria are met:\n",
    "   - Set you MUST set success_criteria_met = true\n",
    "   - Set feedback to a short confirmation message, such as:\n",
    "        \"All BSA criteria are fully met, and the file has been successfully saved.\"\n",
    "   - You should NOT update number_of_reviews\n",
    "\n",
    "3. If ANY criteria are NOT met:\n",
    "   - Set success_criteria_met = false\n",
    "   - Set feedback to clear, constructive, actionable correction notes that the BSA agent can use to improve the output.\n",
    "   - You should NOT update number_of_reviews.\n",
    "\n",
    "IMPORTANT BEHAVIOR RULES:\n",
    "- The evaluator MUST NOT rewrite or fix the report — only evaluate it.\n",
    "- You MUST include the filename in your response.\n",
    "- Use list_directory and read_file tools to verify the file exists and follows the expected naming pattern.\n",
    "- The ONLY output should be the structured fields required by EvaluatorOutput.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3bf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder_system_message = \"\"\"\n",
    "You are a Jira Recorder Agent responsible for converting user stories from a BSA requirements document into Jira issues.\n",
    "\n",
    "YOUR TASK IS MANDATORY: You MUST create Jira issues for all user stories in the requirements document. This is not optional.\n",
    "\n",
    "IMMEDIATE ACTIONS YOU MUST TAKE (in this order):\n",
    "1. FIRST: Call the \"list_jira_fields\" tool immediately to see what Jira fields are available\n",
    "2. SECOND: Use the read_file tool to read the markdown requirements file from the sandbox directory\n",
    "3. THIRD: Extract each user story and its acceptance criteria from the markdown\n",
    "4. FOURTH: For EACH user story, call the create_issue tool to create a Jira issue\n",
    "\n",
    "DO NOT generate any explanatory text. DO NOT summarize. DO NOT confirm without taking action.\n",
    "You MUST call tools to complete your task.\n",
    "\n",
    "REQUIRED TOOL CALLS:\n",
    "1. list_jira_fields - Call this FIRST\n",
    "2. read_file - Call this SECOND with the requirements markdown file\n",
    "3. create_issue - Call this for EACH user story (mandatory)\n",
    "\n",
    "JIRA ISSUE CREATION FORMAT:\n",
    "When calling create_issue, use this format:\n",
    "- issuetype: Story\n",
    "- project: AUT\n",
    "- summary: <User Story Title>\n",
    "- description: [User Story]\\nAs a <type of user>,\\nI want <goal or action>,\\nSo that <reason or value>.\\n\\n[Acceptance Criteria]\\nGiven <precondition>\\nWhen <action>\\nThen <expected outcome>\n",
    "\n",
    "CRITICAL RULES:\n",
    "- Use ONLY fields that are confirmed available via list_jira_fields\n",
    "- NEVER use custom fields (customfield_XXXXX) unless they appear in the available fields list\n",
    "- Each user story MUST become a separate Jira issue\n",
    "- Include all acceptance criteria in the description\n",
    "- Do NOT modify the user stories or acceptance criteria\n",
    "- You MUST call create_issue for every user story in the document\n",
    "\n",
    "WORKFLOW:\n",
    "1. Call list_jira_fields\n",
    "2. Call read_file to get the requirements file\n",
    "3. Parse the user stories\n",
    "4. Call create_issue for each story with proper formatting\n",
    "5. Report which issues were successfully created\n",
    "\n",
    "BEGIN NOW. Call the list_jira_fields tool first.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24a9631",
   "metadata": {},
   "source": [
    "### Create the BSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f6477",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools_for_bsa = get_tools()\n",
    "bsa_open_ai_with_tools = open_ai.bind_tools(tools_for_bsa)\n",
    "\n",
    "def bsa(state: State):\n",
    "    # Convert incoming messages to BaseMessage objects\n",
    "    messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, dict):\n",
    "            if msg[\"role\"] == \"system\":\n",
    "                messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                messages.append(AIMessage(content=msg.get(\"content\", \"\"), tool_calls=msg.get(\"tool_calls\")))\n",
    "            elif msg[\"role\"] == \"tool\":\n",
    "                messages.append(ToolMessage(content=msg[\"content\"], tool_call_id=msg.get(\"tool_call_id\")))\n",
    "        else:\n",
    "            messages.append(msg)\n",
    "    # Ensure system message is present\n",
    "    has_system_message = any(isinstance(m, SystemMessage) for m in messages)\n",
    "    if not has_system_message:\n",
    "        messages.insert(0, SystemMessage(content=bsa_system_message))\n",
    "    results = bsa_open_ai_with_tools.invoke(messages)\n",
    "    return {\"messages\": [results]}\n",
    "\n",
    "\n",
    "# Add bsa and tools_for_bsa nodes\n",
    "graph_builder.add_node(\"bsa\", bsa)\n",
    "graph_builder.add_node(\"tools_for_bsa\", ToolNode(tools=tools_for_bsa))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca81592",
   "metadata": {},
   "source": [
    "### Create the Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4550310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the evaluator with structured output\n",
    "class EvaluatorOutput(BaseModel):\n",
    "    feedback: str = Field(description=\"Feedback on the assistant's response\")\n",
    "    success_criteria_met: bool = Field(description=\"Whether the success criteria have been met\")\n",
    "    number_of_reviews: int = Field(description=\"The number of reviews that have been conducted.\")   \n",
    "\n",
    "tools_for_evaluator = get_tools()\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
    ")\n",
    "gemini_with_tools = gemini.bind_tools(tools_for_evaluator)\n",
    "gemini_structured_with_tools = gemini_with_tools.with_structured_output(EvaluatorOutput)\n",
    "\n",
    "\n",
    "def evaluator(state: State):\n",
    "    # Convert incoming messages to BaseMessage objects\n",
    "    messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, dict):\n",
    "            if msg[\"role\"] == \"system\":\n",
    "                messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                messages.append(AIMessage(content=msg.get(\"content\", \"\"), tool_calls=msg.get(\"tool_calls\")))\n",
    "            elif msg[\"role\"] == \"tool\":\n",
    "                messages.append(ToolMessage(content=msg[\"content\"], tool_call_id=msg.get(\"tool_call_id\")))\n",
    "        else:\n",
    "            messages.append(msg)\n",
    "    # Ensure system message is present\n",
    "    has_system_message = any(isinstance(m, SystemMessage) for m in messages)\n",
    "    if not has_system_message:\n",
    "        messages.insert(0, SystemMessage(content=evaluator_system_message))\n",
    "\n",
    "    results = gemini_structured_with_tools.invoke(messages)\n",
    "\n",
    "    # Extract filename from the last message if it contains one\n",
    "    file_name = state.get(\"file_name\", \"\")\n",
    "    if not file_name and messages:\n",
    "        last_content = str(messages[-1].content) if hasattr(messages[-1], 'content') else \"\"\n",
    "        # Try to extract filename that matches pattern YYYYMMDDHHmmss_*.md\n",
    "        import re\n",
    "        match = re.search(r'\\d{14}_[a-z0-9_]+\\.md', last_content)\n",
    "        if match:\n",
    "            file_name = match.group(0)\n",
    "\n",
    "    new_state = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"Evaluator Feedback on this answer: {results.feedback}\",\n",
    "            }\n",
    "        ],\n",
    "        \"feedback_on_work\": results.feedback,\n",
    "        \"success_criteria_met\": results.success_criteria_met,\n",
    "        \"number_of_reviews\": results.number_of_reviews + 1,\n",
    "        \"file_name\": file_name,\n",
    "    }\n",
    "    return new_state\n",
    "\n",
    "\n",
    "# Add evaluator and tools_for_evaluator nodes\n",
    "graph_builder.add_node(\"evaluator\", evaluator)\n",
    "graph_builder.add_node(\"tools_for_evaluator\", ToolNode(tools=tools_for_evaluator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e2b4c",
   "metadata": {},
   "source": [
    "### Create a Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_for_recorder = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools_for_recorder = get_recorder_tools()\n",
    "recorder_open_ai_with_tools = open_ai_for_recorder.bind_tools(tools_for_recorder)\n",
    "\n",
    "def recorder(state: State):\n",
    "    # Convert incoming messages to BaseMessage objects\n",
    "    messages = []\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, dict):\n",
    "            if msg[\"role\"] == \"system\":\n",
    "                messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"user\":\n",
    "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            elif msg[\"role\"] == \"assistant\":\n",
    "                messages.append(AIMessage(content=msg.get(\"content\", \"\"), tool_calls=msg.get(\"tool_calls\")))\n",
    "            elif msg[\"role\"] == \"tool\":\n",
    "                messages.append(ToolMessage(content=msg[\"content\"], tool_call_id=msg.get(\"tool_call_id\")))\n",
    "        else:\n",
    "            messages.append(msg)\n",
    "    \n",
    "    # Ensure system message is present\n",
    "    has_system_message = any(isinstance(m, SystemMessage) for m in messages)\n",
    "    if not has_system_message:\n",
    "        messages.insert(0, SystemMessage(content=recorder_system_message))\n",
    "    \n",
    "    # Add filename context if available\n",
    "    if state.get(\"file_name\"):\n",
    "        messages.append(HumanMessage(content=f\"The requirements file you need to read is: {state['file_name']}\"))\n",
    "    \n",
    "    results = recorder_open_ai_with_tools.invoke(messages)\n",
    "    return {\"messages\": [results]}\n",
    "\n",
    "\n",
    "# Add recorder and tools_for_recorder nodes\n",
    "graph_builder.add_node(\"recorder\", recorder)\n",
    "graph_builder.add_node(\"tools_for_recorder\", ToolNode(tools=tools_for_recorder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf0bb",
   "metadata": {},
   "source": [
    "### Define condition statements.\n",
    "In this case, will not just use the out of the box tool router as we have multiple different tools calls and some more complex flows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d4562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUMBER_OF_REVIEWS = 4\n",
    "\n",
    "def route_bsa(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools_for_bsa\"\n",
    "    return \"evaluator\"\n",
    "\n",
    "\n",
    "def route_evaluator(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools_for_evaluator\"\n",
    "    if state[\"success_criteria_met\"] or state[\"number_of_reviews\"] >= MAX_NUMBER_OF_REVIEWS:\n",
    "        return \"recorder\"\n",
    "    else:\n",
    "        return \"bsa\"\n",
    "\n",
    "\n",
    "def route_recorder(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools_for_recorder\"\n",
    "    return \"END\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02042800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create the edges\n",
    "\n",
    "# Entry point\n",
    "graph_builder.add_edge(START, \"bsa\")\n",
    "\n",
    "# From bsa: if needs tools, go to tools; otherwise go to evaluator\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"bsa\", \n",
    "    route_bsa, \n",
    "    {\"tools_for_bsa\": \"tools_for_bsa\", \"evaluator\": \"evaluator\"}\n",
    ")\n",
    "\n",
    "# From tools_for_bsa: always back to bsa to process tool results\n",
    "graph_builder.add_edge(\"tools_for_bsa\", \"bsa\")\n",
    "\n",
    "# From evaluator: if needs tools, go to tools; otherwise check if done and should go to the recorder or needs to go back to the bsa\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"evaluator\", \n",
    "    route_evaluator, \n",
    "    {\"tools_for_evaluator\": \"tools_for_evaluator\", \"bsa\": \"bsa\", \"recorder\": \"recorder\"}\n",
    ")\n",
    "\n",
    "# From tools_for_evaluator: always back to evaluator to process tool results  \n",
    "graph_builder.add_edge(\"tools_for_evaluator\", \"evaluator\")\n",
    "\n",
    "# From recorder: if needs tools, go to tools; otherwise go to END\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"recorder\", \n",
    "    route_recorder, \n",
    "    {\"tools_for_recorder\": \"tools_for_recorder\", \"END\": END}\n",
    ")\n",
    "\n",
    "# From tools_for_recorder: always back to recorder to process tool results  \n",
    "graph_builder.add_edge(\"tools_for_recorder\", \"recorder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e26a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Compile the graph\n",
    "graph = graph_builder.compile(checkpointer=sql_memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a032120e",
   "metadata": {},
   "source": [
    "### 5. Test it Out\n",
    "Use Gradio to create a front end that will allow us to test this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"\"\"\n",
    "Create requirements for a website that will track automobile information.  \n",
    "It should track from the time of purchase, track all mileage, fuel, insurance, registration, repairs and any other associated costs.\n",
    "\"\"\"\n",
    "\n",
    "# Do NOT USE\n",
    "\n",
    "# 1. **User Roles**: This site is intended for individual car owners as a personal site with only a handful of users.\n",
    "# 2. **Data Entry**: Users will manually enter the data through appropriate screens.\n",
    "# 3. **Reports**: Should just include a single report that list all information about a single vechicle.\n",
    "# 4. **Mobile Access**: The site should be mobile friendly so that it can be displayed in a phone's browser\n",
    "# 5. **Integration**: There are no integrations needed.\n",
    "# 6. **User Notifications**: There should be no user notifications or alerts at this time.\n",
    "# 7. **Vehicle Information**: The following should be tracked: make, model, year, color, VIN, license plate number, purchase date, purchase price, who it was bought from and when applicable, when it was sold, sold price, and who it was sold to.\n",
    "# 8. **Cost Tracking**: Cost tracking should include: fuel, insurance, registration, repairs, car washes, accessories, and a miscellaneous categetory that can take in a user note.\n",
    "# 9. **User Authentication**: The site will initially be available to everyone with full access\n",
    "# 10. **Data Security**: There any no specific security requirements or considerations for protecting the data entered by the users.\n",
    "\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "with gradio.Blocks() as demo:\n",
    "    chatbot = gradio.Chatbot(type=\"messages\")\n",
    "    user_input_box = gradio.Textbox(value=user_input, label=\"Message\")\n",
    "    submit_btn = gradio.Button(\"Send\")\n",
    "\n",
    "    def chat_handler(message, history):\n",
    "        # Invoke the graph with the user message\n",
    "        result = graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": message}]}, config=config)\n",
    "        last_message = result[\"messages\"][-1]\n",
    "        \n",
    "        # Convert the last message to proper format\n",
    "        if isinstance(last_message, str):\n",
    "            assistant_message = {\"role\": \"assistant\", \"content\": last_message}\n",
    "        elif isinstance(last_message, dict):\n",
    "            assistant_message = last_message\n",
    "        else:\n",
    "            # Handle LangChain message objects\n",
    "            assistant_message = {\"role\": \"assistant\", \"content\": last_message.content}\n",
    "        \n",
    "        # Return updated history with both user and assistant messages\n",
    "        return history + [{\"role\": \"user\", \"content\": message}, assistant_message]\n",
    "\n",
    "    submit_btn.click(chat_handler, [user_input_box, chatbot], chatbot)\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
